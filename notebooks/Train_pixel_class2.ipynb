{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPirqWjq/aYXVsClYX/3Enm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mille055/AIPI540_individual_project/blob/main/notebooks/Train_pixel_class2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SOgupA0b7-T",
        "outputId": "dce4e95a-38f5-4b12-c8c3-04b5b8ba7cd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Connect to the data which is in Google Drive\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#install pydicom for reading the dicom data\n",
        "!pip install pydicom monai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IsUcTeyeaYt",
        "outputId": "72aab477-88c0-4106-d0e3-663e56fb83df"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pydicom\n",
            "  Downloading pydicom-2.3.1-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting monai\n",
            "  Downloading monai-1.1.0-202212191849-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from monai) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.9/dist-packages (from monai) (2.0.0+cu118)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8->monai) (2.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.8->monai) (3.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.8->monai) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8->monai) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.8->monai) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.8->monai) (3.11.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.8->monai) (16.0.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.8->monai) (3.25.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.8->monai) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.8->monai) (1.3.0)\n",
            "Installing collected packages: pydicom, monai\n",
            "Successfully installed monai-1.1.0 pydicom-2.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "from __future__ import print_function\n",
        "import sys\n",
        "from random import shuffle\n",
        "\n",
        "import os\n",
        "import os.path\n",
        "import glob\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import csv\n",
        "import pydicom\n",
        "import cv2\n",
        "import configparser\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.backends.cudnn as cudnn\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "import monai\n",
        "from monai.data import DataLoader, ImageDataset\n",
        "from monai.transforms import AddChannel, Compose, RandRotate90, Resize, ScaleIntensity, EnsureType\n"
      ],
      "metadata": {
        "id": "ExBLTmqAb-rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/gdrive/MyDrive/WW_MRI_abd2/split/new_csv/'\n",
        "#train_df = pd.read_pickle(data_dir+'train_img_df.pkl')\n",
        "#test_df = pd.read_pickle(data_dir+'test_img_df.pkl')\n",
        "train_csv = pd.read_csv(data_dir + 'trainfiles.csv')\n",
        "val_csv = pd.read_csv(data_dir+'valfiles.csv')\n",
        "test_csv = pd.read_csv(data_dir + 'testfiles.csv')\n",
        "\n",
        "#run once at start to rid unneccesary column\n",
        "# train_csv.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "# test_csv.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "sQr7s1iMeX1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bySHnCmafoF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #train_get_mid = train_csv.groupby(['patientID', 'series']).agg({'img_num': lambda x: sorted(x.to_list())})\n",
        "# df = train_csv.copy()\n",
        "\n",
        "# grouped_df = df.groupby(['patientID', 'series'])\n",
        "# sorted_df = grouped_df['file_info'].apply(lambda x: x.sort_values())\n",
        "# sorted_df\n",
        "# middle_filename = grouped_df['file_info'].apply(lambda x: x.sort_values().iloc[len(x)//2])\n",
        "# middle_filename = middle_filename.reset_index()\n",
        "# df = df.merge(middle_filename, on=['patientID', 'series'], how='left')\n",
        "# pd.options.display.max_colwidth = 100\n",
        "# train_csv_short = df.drop(['file_info_x', 'img_num'], axis=1)\n",
        "# train_csv_short.rename(columns = {'file_info_y': 'file_info'})\n",
        "# train_csv_short.drop_duplicates(inplace=True)\n",
        "# train_csv_short\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uIJqJA0jVkYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this function will select the image in the middle of each series of images, so that only a single image from each series is selected for training\n",
        "# There is one image from each series for each patient\n",
        "def shorten_df(df, selection_fraction = 0.5):\n",
        "  df1 = df.copy()\n",
        "  grouped_df = df.groupby(['patientID', 'series'])\n",
        "  sorted_df = grouped_df['file_info'].apply(lambda x: x.sort_values())\n",
        "  \n",
        "  selected_filename = grouped_df['file_info'].apply(lambda x: x.sort_values().iloc[int(len(x)*selection_fraction)])\n",
        "\n",
        "  \n",
        "  selected_filename = selected_filename.reset_index()\n",
        "  \n",
        "  # perform merge and deal with duplicate/unnecessary columns\n",
        "  df1 = df1.merge(selected_filename, on=['patientID', 'series'], how='left') \n",
        "  df_short = df1.drop(['file_info_x', 'img_num'], axis=1)\n",
        "  df_short = df_short.rename(columns = {'file_info_y': 'file_info'})\n",
        "  df_short.drop_duplicates(inplace=True)\n",
        "  df_short.reset_index(drop=True, inplace=True)\n",
        "  return df_short"
      ],
      "metadata": {
        "id": "q2Xn8kRJtld2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create shortened dataframes for train and test\n",
        "train = shorten_df(train_csv, selection_fraction = 0.5)\n",
        "test = shorten_df(test_csv, selection_fraction = 0.5)\n",
        "val = shorten_df(val_csv, selection_fraction=0.5)"
      ],
      "metadata": {
        "id": "Fa5V-Hg2tvcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "id": "8soeIs5GuhQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #create train, val, and test datasets from the csv files, using same val list as metadata classifier\n",
        "\n",
        "# #using same train/val/test split as in the original split based on the metadata classifier\n",
        "# val_list = [41, 84, 14, 25, 76, 47,62,0,55,63,101,18,81,3,4,95,66]\n",
        "\n",
        "# val_df = train_csv_short[train_csv_short.patientID.isin(val_list)]\n",
        "# train_df = train_csv_short[~train_csv_short.index.isin(val_df.index)]\n",
        "# test_df = test_csv_short\n",
        "\n",
        "# ## exclude the nonclinical and infrequent series to match the metadata model\n",
        "# exclusion_labels = [1, 21,22,26,27,28,29]\n",
        "# val_df = val_df[~val_df.label.isin(exclusion_labels)]\n",
        "# train_df = train_df[~train_df.label.isin(exclusion_labels)]\n",
        "# test_df = test_df[~test_df.label.isin(exclusion_labels)]\n",
        "\n",
        "# train = train_df.reset_index(drop=True)\n",
        "# val = val_df.reset_index(drop=True)\n",
        "# test = test_df.reset_index(drop=True)\n",
        "\n",
        "# #sanity check\n",
        "# print(len(val)+len(train), len(test))\n",
        "# display(val.head(), train.head())"
      ],
      "metadata": {
        "id": "NBaqTfsYeTNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.label.value_counts()"
      ],
      "metadata": {
        "id": "WeAaM_6Jzpnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data cropping and normalization, also converts single channel to 3 channel for the model\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize(299),\n",
        "        transforms.CenterCrop(299),\n",
        "        #transforms.RandomHorizontalFlip(),\n",
        "        transforms.Grayscale(num_output_channels=3),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize(299),\n",
        "        transforms.CenterCrop(299),\n",
        "        transforms.Grayscale(num_output_channels=3),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize(299),\n",
        "        transforms.CenterCrop(299),\n",
        "        transforms.Grayscale(num_output_channels=3),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "}"
      ],
      "metadata": {
        "id": "HhiPdrdNftaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RqDJSBg9YEgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# custom datasest - gets the image data using pydicom.dcmread and transforms\n",
        "# also gets label from the label column and merges classes 2-5 which are all flavors\n",
        "# arterial into a single 'arterial' label as label 2\n",
        "\n",
        "class ImgDataset(Dataset):\n",
        "    def __init__(self, df, transform=None):\n",
        "        self.data_df = df\n",
        "        self.datafileslist = df.file_info\n",
        "        self.labels = df.label\n",
        "        self.transform = transform\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.data_df.shape[0]\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        source = '/volumes/cm7/Abdominal_MRI_dataset_split/'\n",
        "        dest = '/content/gdrive/MyDrive/WW_MRI_abd2/split/'\n",
        "\n",
        "        img_file = self.data_df.file_info[idx]\n",
        "        rel = os.path.relpath(img_file, source)\n",
        "        img_file_new = os.path.join(dest,rel)\n",
        "        \n",
        "        #print('getting file', img_file)\n",
        "        ds = pydicom.dcmread(img_file_new)\n",
        "        img = np.array(ds.pixel_array, dtype=np.float32)\n",
        "        #img = img/255.\n",
        "        #img = cv2.resize(img, (224,224))\n",
        "        img = img[np.newaxis]\n",
        "        img = torch.from_numpy(np.asarray(img))\n",
        "        \n",
        "        #print(img.dtype, img.shape)\n",
        "        \n",
        "        \n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        #print('after transform', img.dtype, img.shape)\n",
        "            \n",
        "        x = img\n",
        "        labl = self.data_df.label[idx]\n",
        "        actual_classes = [0,2,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,23,25]\n",
        "        adjusted_label = actual_classes.index(labl)\n",
        "        y = torch.tensor(adjusted_label, dtype=torch.long)  # Use torch.long instead of torch.float32\n",
        "      \n",
        "        #print(x,y)\n",
        "        return (x,y)\n",
        "        "
      ],
      "metadata": {
        "id": "Xu4-zLcGggeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual_classes = [0,2,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,23,25]"
      ],
      "metadata": {
        "id": "torHCBpSt1ib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataloaders\n",
        "train_imgdata = ImgDataset(train, data_transforms['train'])\n",
        "train_loader = DataLoader(train_imgdata, batch_size=8, shuffle=True)\n",
        "\n",
        "val_imgdata = ImgDataset(val, data_transforms['val'])\n",
        "val_loader = DataLoader(val_imgdata, batch_size=8, shuffle=True)\n",
        "\n",
        "test_imgdata = ImgDataset(test, data_transforms['test'])\n",
        "test_loader = DataLoader(test_imgdata, batch_size=8, shuffle=False)\n",
        "\n",
        "dataset_sizes = {'train':len(train_imgdata),'val':len(val_imgdata)}\n"
      ],
      "metadata": {
        "id": "ArGxGwPlgp0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hZ0yXsC6BJY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualization\n",
        "def imshow(img, title):\n",
        "    img = torchvision.utils.make_grid(img, normalize=True)\n",
        "    npimg = img.numpy()\n",
        "    fig = plt.figure(figsize = (5, 15))\n",
        "    plt.imshow(np.transpose(npimg,(1,2,0)))\n",
        "    plt.title(title)\n",
        "\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "b33ZnB1xg8wJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_next_batch = next(iter(test_loader))\n",
        "#print(train_next_batch[0])\n",
        "imshow(test_next_batch[0], (test_next_batch[1]))"
      ],
      "metadata": {
        "id": "SK9F-Rtfg4WX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FoMdoW8WhOzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    dataloaders = {'train': train_loader, 'val': val_loader, 'test': test_loader}\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            batch_num = 0\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                print('batch ', batch_num)\n",
        "                batch_num= batch_num + 1\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.type(torch.LongTensor)\n",
        "                labels = labels.to(device)\n",
        "                \n",
        "                \n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "    print(f'Best val Acc: {best_acc:4f}')\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "metadata": {
        "id": "ZCWLMFawAIhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.type(torch.LongTensor)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title(f'predicted: {class_names[preds[j]]}')\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)"
      ],
      "metadata": {
        "id": "088uAAf_OGPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cqxlXfIcdM85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use resnet50 transfer learning\n",
        "model_ft = models.resnet50(pretrained=True)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "\n",
        "# output\n",
        "model_ft.fc = nn.Linear(num_ftrs, 19)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "SnLg2lelOHet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train model for 25 epochs\n",
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=25)"
      ],
      "metadata": {
        "id": "Zv-rn8rG-mMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inverse_adjust_labels(new_label):\n",
        "    return int(actual_classes[new_label])\n"
      ],
      "metadata": {
        "id": "tZ3lpbEkI64Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display a batch of predictions\n",
        "\n",
        "def visualize_results(model,dataloader,device):\n",
        "    model = model.to(device) # Send model to GPU if available\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        # Get a batch of validation images\n",
        "        images, labels = next(iter(val_loader))\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        # Get predictions\n",
        "        _,preds = torch.max(model(images), 1)\n",
        "        preds = np.squeeze(preds.cpu().numpy())\n",
        "        images = images.cpu().numpy()\n",
        "\n",
        "    # Plot the images in the batch, along with predicted and true labels\n",
        "    fig = plt.figure(figsize=(15, 10))\n",
        "    for idx in np.arange(len(preds)):\n",
        "        ax = fig.add_subplot(2, len(preds)//2, idx+1, xticks=[], yticks=[])\n",
        "        image = images[idx]\n",
        "        image = image.transpose((1, 2, 0))\n",
        "        mean = np.array([0.485, 0.456, 0.406])\n",
        "        std = np.array([0.229, 0.224, 0.225])\n",
        "        image = (std * image + mean)\n",
        "        \n",
        "        image = np.clip(image, 0, 1)\n",
        "        ax.imshow(image)\n",
        "        ax.set_title(\"{} ({})\".format(actual_classes[preds[idx]], actual_classes[labels[idx]]),\n",
        "                    color=(\"green\" if preds[idx]==labels[idx] else \"red\"))\n",
        "    return\n",
        "\n",
        "visualize_results(model_ft,val_loader,device)"
      ],
      "metadata": {
        "id": "qbITn4vDT3JX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model,test_loader,device):\n",
        "    model = model.to(device)\n",
        "    # Turn autograd off\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # Set the model to evaluation mode\n",
        "        model.eval()\n",
        "\n",
        "        # Set up lists to store true and predicted values\n",
        "        y_true = []\n",
        "        test_preds = []\n",
        "\n",
        "        # Calculate the predictions on the test set and add to list\n",
        "        for data in test_loader:\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "            # Feed inputs through model to get raw scores\n",
        "            logits = model.forward(inputs)\n",
        "            #print(labels, logits.sum())\n",
        "            # Convert raw scores to probabilities (not necessary since we just care about discrete probs in this case)\n",
        "            probs = torch.softmax(logits, dim=1)\n",
        "            probs = probs.detach().cpu().numpy()\n",
        "            #print(labels, probs)\n",
        "            # Get discrete predictions using argmax\n",
        "            preds = np.argmax(probs,axis=1)\n",
        "            # Add predictions and actuals to lists\n",
        "            test_preds.extend(preds)\n",
        "            y_true.extend(labels.detach().cpu().numpy())\n",
        "\n",
        "        # Calculate the accuracy\n",
        "        test_preds = np.array(test_preds)\n",
        "        y_true = np.array(y_true)\n",
        "        test_acc = np.sum(test_preds == y_true)/y_true.shape[0]\n",
        "        \n",
        "        # Recall for each class\n",
        "        recall_vals = []\n",
        "        for i in range(30):\n",
        "            class_idx = np.argwhere(y_true==i)\n",
        "            total = len(class_idx)\n",
        "            correct = np.sum(test_preds[class_idx]==i)\n",
        "            recall = correct / total\n",
        "            recall_vals.append(recall)\n",
        "    \n",
        "    return test_acc,recall_vals, test_preds, y_true"
      ],
      "metadata": {
        "id": "P1m0epNS98mE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RsU7U6-clC63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_EkR22cSlg61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the pre-trained model\n",
        "#classes = set(train.label)\n",
        "acc,recall_vals, test_preds, ytrue = test_model(model_ft,test_loader,device)\n",
        "print('Test set accuracy is {:.3f}'.format(acc))\n",
        "\n",
        "\n",
        "for i in range(len(recall_vals)):\n",
        "    print('For class {}, recall is {}'.format(i,recall_vals[i]))"
      ],
      "metadata": {
        "id": "_dLjJNtc5dMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay, classification_report, confusion_matrix\n",
        "ConfusionMatrixDisplay.from_predictions(ytrue, test_preds)"
      ],
      "metadata": {
        "id": "OEb94GH2kCuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "abd_label_dict_updated = {\n",
        "    '1': {\n",
        "        'long': 'Anythingelse',\n",
        "        'short': 'other',\n",
        "        'plane': 'other',\n",
        "        'contrast': 'other'\n",
        "    },\n",
        "    '2': {\n",
        "        'long': 'Arterial T1w',\n",
        "        'short': 'arterial',\n",
        "        'plane': 'ax',\n",
        "        'contrast': '1'\n",
        "    },\n",
        "    '3': {\n",
        "        'long': 'Early Arterial T1w',\n",
        "        'short': 'early_arterial',\n",
        "        'plane': 'ax',\n",
        "        'contrast': '1'\n",
        "    },\n",
        "    '4': {\n",
        "        'long': 'Late Arterial T1w',\n",
        "        'short': 'late_arterial',\n",
        "        'plane': 'ax',\n",
        "        'contrast': '1'\n",
        "    },\n",
        "    '5': {\n",
        "        'long': 'Arterial Subtraction',\n",
        "        'short': 'arterial_sub',\n",
        "        'plane': 'ax',\n",
        "        'contrast': '1'\n",
        "    },\n",
        "    '6': {\n",
        "        'long': 'Coronal Late Dynamic T1w',\n",
        "        'short': 'dynamic_late',\n",
        "        'plane': 'cor',\n",
        "        'contrast': '1'\n",
        "    },\n",
        "    '7': {\n",
        "        'long': 'Coronal T2w',\n",
        "        'short': 't2',\n",
        "        'plane': 'cor',\n",
        "        'contrast': '0'\n",
        "    },\n",
        "    '8': {\n",
        "        'long': 'Axial DWI',\n",
        "        'short': 'dwi',\n",
        "        'plane': 'ax',\n",
        "        'contrast': '0'\n",
        "    },\n",
        "    '9': {\n",
        "        'long': 'Axial T2w',\n",
        "        'short': 't2',\n",
        "        'plane': 'ax',\n",
        "        'contrast': '0'\n",
        "    },\n",
        "    '10': {\n",
        "        'long': 'Coronal DWI',\n",
        "        'short': 'dwi',\n",
        "        'plane': 'cor',\n",
        "        'contrast': '0'\n",
        "    },\n",
        "    '11': {\n",
        "        'long': 'Fat Only',\n",
        "        'short': 'dixon_fat',\n",
        "        'plane': 'ax',\n",
        "        'contrast': '0'\n",
        "    },\n",
        "    '12': {\n",
        "        'long': 'Axial Transitional_Hepatocyte T1w',\n",
        "        'short': 'hepatobiliary',\n",
        "        'plane': 'ax',\n",
        "        'contrast': '1'\n",
        "    },\n",
        "    '13': {\n",
        "        'long': 'Coronal Transitional_Hepatocyte T1w',\n",
        "        'short': 'hepatobiliary',\n",
        "        'plane': 'cor',\n",
        "        'contrast': '1'\n",
        "    },\n",
        "    '14': {\n",
        "        'long': 'Axial In Phase',\n",
        "        'short': 'in_phase',\n",
        "        'plane': 'ax',\n",
        "        'contrast': '0'\n",
        "    },\n",
        "    '15': {\n",
        "        'long': 'Coronal In Phase',\n",
        "        'short': 'in_phase',\n",
        "        'plane': 'cor',\n",
        "        'contrast': '0'\n",
        "    },\n",
        "    '16': {\n",
        "        'long': 'Axial Late Dyanmic T1w',\n",
        "        'short': 'dynamic_equilibrium',\n",
        "        'plane': 'ax',\n",
        "        'contrast': '1'\n",
        "    },\n",
        "    '17': {\n",
        "        'long': 'Localizers',\n",
        "        'short': 'loc',\n",
        "        'plane': 'unknown',\n",
        "        'contrast': '0'\n",
        "    },\n",
        "    '18': {\n",
        "        'long': 'MRCP',\n",
        "        'short': 'mrcp',\n",
        "        'plane': 'cor',\n",
        "        'contrast': '0'\n",
        "    },\n",
        "    '19': {\n",
        "        'long': 'Axial Opposed Phase',\n",
        "        'short': 'opposed_phase',\n",
        "        'plane': 'ax',\n",
        "        'contrast': '0'\n",
        "    },\n",
        "    '20': {\n",
        "        'long': 'Coronal Opposed Phase',\n",
        "        'short': 'opposed_phase',\n",
        "        'plane': 'cor',\n",
        "        'contrast': '0'\n",
        "    },\n",
        "    '21': {\n",
        "        'long': 'Proton Density Fat Fraction',\n",
        "        'short': 'fat_quant',\n",
        "        'plane': 'ax',\n",
        "        'contrast': '0'\n",
        "    },\n",
        "    '22': {\n",
        "        'long': 'Water Density Fat Fraction',\n",
        "        'short': 'water_fat_quant',\n",
        "        'plane': 'ax',\n",
        "        'contrast': '0'\n",
        "    },\n",
        "    '23': {\n",
        "        'long': 'Portal Venous T1w',\n",
        "        'short': 'portal_venous',\n",
        "        'plane': 'ax',\n",
        "        'contrast': '1'\n",
        "    },\n",
        "    '24': {\n",
        "        'long': 'Coronal Precontrast Fat Suppressed T1w',\n",
        "        'short': 't1_fat_sat',\n",
        "        'plane': 'cor',\n",
        "        'contrast': '0'\n",
        "    },\n",
        "    '25': {\n",
        "        'long': 'Axial Precontrast Fat Suppressed T1w',\n",
        "        'short': 't1_fat_sat',\n",
        "        'plane': 'ax',\n",
        "        'contrast': '0'\n",
        "    },\n",
        "    '26': {\n",
        "        'long': 'R*2',\n",
        "        'short': 'r_star_2',\n",
        "        'plane': 'ax',\n",
        "        'contrast': '0'\n",
        "    },\n",
        "    '27': {\n",
        "        'long': 'Axial Steady State Free Precession',\n",
        "        'short': 'ssfse',\n",
        "        'plane': 'ax',\n",
        "        'contrast': '0'\n",
        "    },\n",
        "    '28': {\n",
        "        'long': 'Coronal Steady State Free Precession',\n",
        "        'short': 'ssfse',\n",
        "        'plane': 'cor',\n",
        "        'contrast': '1'\n",
        "    },\n",
        "    '29': {\n",
        "        'long': 'Venous Subtraction',\n",
        "        'short': 'venous_sub',\n",
        "        'plane': 'ax',\n",
        "        'contrast': '1'\n",
        "    },\n",
        "    '0': {\n",
        "        'long': 'Axial ADC',\n",
        "        'short': 'adc',\n",
        "        'plane': 'ax',\n",
        "        'contrast': '0'\n",
        "    },\n",
        "     '30': {\n",
        "        'long': 'Axial Post Contrast Fat Suppressed T1w',\n",
        "        'short': 't1_fat_sat',\n",
        "        'plane': 'ax',\n",
        "        'contrast': '1'\n",
        "    },\n",
        "    '31': {\n",
        "        'long': 'Coronal Post Contrast Fat Suppressed T1w',\n",
        "        'short': 't1_fat_sat',\n",
        "        'plane': 'cor',\n",
        "        'contrast': '1'\n",
        "    },\n",
        "    '32': {\n",
        "        'long': 'Post Contrast Fat Suppressed T1w',\n",
        "        'short': 't1_fat_sat',\n",
        "        'plane': 'ax/cor',\n",
        "        'contrast': '1'\n",
        "    }\n",
        "}\n",
        "yvals= set(list(ytrue))\n",
        "yvals = [str(int(x)) for x in yvals]\n",
        "\n",
        "target_names = [abd_label_dict_updated[str(x)] ['short'] for x in yvals]\n",
        "cm = confusion_matrix(ytrue, test_preds)\n",
        "plt.figure(figsize=(25, 25))\n",
        "plt.tight_layout()\n",
        "ConfusionMatrixDisplay(cm, display_labels=target_names).plot(xticks_rotation = 'vertical', cmap='Blues')\n",
        "plt.savefig(\"FigPixel\"+datetime.now().strftime('%Y%m%d')+\".png\",dpi=300, bbox_inches = 'tight')"
      ],
      "metadata": {
        "id": "XzlZrIos0Dj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(ytrue, test_preds))\n"
      ],
      "metadata": {
        "id": "Kb2sllad5J7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ### save the model from this training run\n",
        "# import pickle\n",
        "# pickle.dump(model_ft, open('pixel_model_single_img_032123.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "LiF9xXXLqQYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model's state_dict\n",
        "torch.save(model_ft.state_dict(), 'pixel_model_041123.pth')"
      ],
      "metadata": {
        "id": "pJDFIioiG0gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test2_csv_short = shorten_df(test_csv, 0.75)\n",
        "test2 = test2_csv_short.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "ZQDAKnHk9f7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_imgdata2 = ImgDataset(test2, data_transforms['test'])\n",
        "test_loader2 = DataLoader(test_imgdata2, batch_size=8, shuffle=False)"
      ],
      "metadata": {
        "id": "5TlTCsZj-vlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testing model trained on images with selection = 0.3 with test where selection = 0.5\n",
        "# Test the pre-trained model\n",
        "#classes = set(train.label)\n",
        "acc2,recall_vals2, test_preds2, ytrue2 = test_model(model_ft,test_loader2,device)\n",
        "print('Test set accuracy is {:.3f}'.format(acc))\n",
        "\n",
        "\n",
        "for i in range(len(recall_vals)):\n",
        "    print('For class {}, recall is {}'.format(i,recall_vals[i]))"
      ],
      "metadata": {
        "id": "vlPkQjZ1-f0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ConfusionMatrixDisplay.from_predictions(ytrue, test_preds2)\n",
        "\n",
        "print(classification_report(ytrue, test_preds2))"
      ],
      "metadata": {
        "id": "4N8q3BtSAI9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_dn = torch.hub.load('pytorch/vision:v0.10.0', 'densenet121', pretrained=True)\n",
        "\n",
        "model_dn.fc = nn.Linear(num_ftrs, 30)\n",
        "model_dn = model_dn.to(device)"
      ],
      "metadata": {
        "id": "IBqZMpwkmZr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_dn = train_model(model_dn, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=25)\n"
      ],
      "metadata": {
        "id": "liDww_eU7IqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the pre-trained model\n",
        "#classes = set(train.label)\n",
        "acc,recall_vals, test_preds, ytrue = test_model(model_ft,test_loader,device)\n",
        "print('Test set accuracy is {:.3f}'.format(acc))\n",
        "\n",
        "\n",
        "for i in range(len(recall_vals)):\n",
        "    print('For class {}, recall is {}'.format(i,recall_vals[i]))"
      ],
      "metadata": {
        "id": "4c8RVJ-O75L6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_iv3 = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True)\n",
        "model_iv3.fc = nn.Linear(num_ftrs, 30)\n",
        "\n",
        "model_iv3 = model_iv3.to(device)"
      ],
      "metadata": {
        "id": "01zzM75T9gwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_iv3 = train_model(model_iv3, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=15)"
      ],
      "metadata": {
        "id": "fZzE6FvvmqNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CfGbbfuB96kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_ft.state_dict(), 'model_res50sel0_3')"
      ],
      "metadata": {
        "id": "0zzOiJ5jlBDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft"
      ],
      "metadata": {
        "id": "WJgThV6F-0LW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Define monai transforms\n",
        "# train_trans_mon = Compose([ScaleIntensity(),  Resize((1, 299, 299)), RandRotate90(), EnsureType()])\n",
        "# val_trans_mon = Compose([ScaleIntensity(), Resize((1, 299, 299)), EnsureType()])\n",
        "\n",
        "# # Create training Dataset and DataLoader using first 10 images\n",
        "# train_ds = ImageDataset(image_files=images[:10], labels=labels[:10], transform=train_trans_mon)\n",
        "# train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=2, pin_memory=torch.cuda.is_available())\n",
        "\n",
        "# # Create validation Dataset and DataLoader using the rest of the images\n",
        "# val_ds = ImageDataset(image_files=images[-10:], labels=labels[-10:], transform=val_transforms)\n",
        "# val_loader = DataLoader(val_ds, batch_size=2, num_workers=2, pin_memory=torch.cuda.is_available())\n",
        "\n",
        "# # Set up dict for dataloaders\n",
        "# dataloaders = {'train':train_loader,'val':val_loader}\n",
        "\n",
        "# # Store size of training and validation sets\n",
        "# dataset_sizes = {'train':len(train_ds),'val':len(val_ds)}\n",
        "\n",
        "# im, label = monai.utils.misc.first(train_loader)\n",
        "# print(f'Image type: {type(im)}')\n",
        "# print(f'Input batch shape: {im.shape}')\n",
        "# print(f'Label batch shape: {label.shape}')"
      ],
      "metadata": {
        "id": "0wzz6RxGnn9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_mon = monai.networks.nets.DenseNet121(spatial_dims=2, in_channels=1, out_channels=30).to(device)"
      ],
      "metadata": {
        "id": "72yRVm5I_78O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use cross-entropy loss function\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "# loss_function = torch.nn.BCEWithLogitsLoss()  # also works with this data\n",
        "\n",
        "# Use Adam adaptive optimizer\n",
        "optimizer = torch.optim.Adam(model_mon.parameters(), 1e-4)\n",
        "\n",
        "# Train the model\n",
        "epochs=10\n",
        "model_mon = train_model(model_mon, criterion, optimizer, exp_lr_scheduler, num_epochs=epochs)"
      ],
      "metadata": {
        "id": "IDdGh3tmAsOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l5WEvr9bBF9P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}