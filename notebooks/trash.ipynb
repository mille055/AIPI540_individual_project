{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLAB_FLAG = False   # whether running on colab or locally on computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB_FLAG:\n",
    "    !pip install pydicom==2.1.2\n",
    "    !pip install monai seaborn sentence_transformers\n",
    "    !git clone 'https://github.com/mille055/AIPI540_individual_project.git'\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import pydicom\n",
    "#import monai\n",
    "import pickle\n",
    "import glob\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, recall_score, plot_confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from pprint import pprint\n",
    "from fastai.basics import delegates\n",
    "from fastcore.parallel import parallel\n",
    "from fastcore.utils import gt\n",
    "from fastcore.foundation import L\n",
    "\n",
    "# import monai\n",
    "# from monai.data import DataLoader, ImageDataset\n",
    "# from monai.transforms import AddChannel, Compose, RandRotate90, Resize, ScaleIntensity, EnsureType\n",
    "from pydicom.dataset import Dataset as DcmDataset\n",
    "from pydicom.tag import BaseTag as DcmTag\n",
    "from pydicom.multival import MultiValue as DcmMultiValue\n",
    "import sys\n",
    "import importlib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#local imports\n",
    "if COLAB_FLAG:\n",
    "    sys.path.append('/content/AIPI540_individual_project/scripts/')\n",
    "    train_datafile = '/content/AIPI540_individual_project/data/trainfiles.csv'\n",
    "    val_datafile = '/content/AIPI540_individual_project/data/valfiles.csv'\n",
    "    test_datafile = '/content/AIPI540_individual_project/data/testfiles.csv'\n",
    "\n",
    "else: # running locally\n",
    "    sys.path.append('/Users/cmm/Documents/GitHub/AIPI540_individual_project/scripts/')\n",
    "    train_datafile = '../data/trainfiles.csv'\n",
    "    val_datafile = '../data/valfiles.csv'\n",
    "    test_datafile = '../data/testfiles.csv'\n",
    "\n",
    "### local imports ###\n",
    "from config import file_dict, feats, feats_to_keep, column_lists, RF_parameters, classes, model_paths\n",
    "from config import abd_label_dict, val_list, train_val_split_percent, random_seed, data_transforms\n",
    "from config import sentence_encoder, series_description_column\n",
    "from utils import *\n",
    "#from train_pixel_model import train_pix_model, test_pix_model, ImgDataset, image_to_tensor, get_pixel_preds_and_probs\n",
    "#from train_meta_model import train_fit_parameter_trial, train_meta_model, calc_feature_importances, get_meta_probs, meta_inference\n",
    "#from train_text_model import train_text_log_model, load_text_data, get_nlp_inference\n",
    "from NLP.NLP_inference import get_NLP_inference\n",
    "from NLP.NLP_training import train_NLP_model\n",
    "from cnn.cnn_dataset import ImgDataset\n",
    "from cnn.cnn_inference import image_to_tensor, pixel_inference, test_pix_model, load_pixel_model, visualize_results\n",
    "from cnn.cnn_model import CustomResNet50\n",
    "from cnn.cnn_data_loaders import get_data_loaders\n",
    "from metadata.meta_inference import meta_inference, calc_feature_importances\n",
    "from metadata.meta_training import train_fit_parameter_trial, train_meta_model, evaluate_meta_model\n",
    "from fusion_model.fus_model import FusionModel\n",
    "from fusion_model.fus_inference import get_fusion_inference\n",
    "from model_container import ModelContainer\n",
    "from process_tree import Processor, write_labels_into_dicom\n",
    "# from AIPI540_individual_project.scripts.train_pixel_model import train_model\n",
    "# from AIPI540_individual_project.scripts.train_text_model import load_text_data, train_text_model, list_incorrect_text_predictions\n",
    "# from AIPI540_individual_project.scripts.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_model = FusionModel\n",
    "\n",
    "class PartialFusionModel(nn.Module):\n",
    "    def __init__(self, model1, model2, num_classes):\n",
    "        super(PartialFusionModel, self).__init__()\n",
    "        self.model1 = model1\n",
    "        self.model2 = model2\n",
    "        #self.model3 = model3\n",
    "        self.fusion_layer = nn.Linear(num_classes * 2, num_classes)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        \n",
    "        x = torch.cat((x1, x2), dim=0)\n",
    "        x = self.fusion_layer(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "partial_fusion_model = PartialFusionModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FusionModel(\n",
      "  (model2): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Linear(in_features=2048, out_features=19, bias=True)\n",
      "  )\n",
      "  (fusion_layer): Linear(in_features=57, out_features=19, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "with open('../models/fusion_model041623.pkl', 'rb') as file:\n",
    "    fusion = pickle.load(file)\n",
    "\n",
    "print(fusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### fix my fusion model issue:; have to change from a pickled model to saved weights\n",
    "def save_fusion_model_weights(pickle_path, weight_path):\n",
    "    with open(pickle_path, 'rb') as file:\n",
    "        fusion_model = pickle.load(file)\n",
    "    torch.save(fusion_model.state_dict(), weight_path)\n",
    "\n",
    "save_fusion_model_weights(model_paths['fusion'], '../models/fusion_saved_weights042123.pth')\n",
    "save_fusion_model_weights('../models/meta_and_pixel_fusion_model041623.pkl', '../models/fusion_saved_weights_no_nlp042123.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### in the fusion model creation code:\n",
    "\n",
    "Xtrain1 = fusion_train_df.meta_probs.values\n",
    "\n",
    "Xtrain2 = fusion_train_df.pixel_probs.values\n",
    "Xtrain3 = fusion_train_df.nlp_probs.values\n",
    "\n",
    "Xtrain1 = np.stack(Xtrain1, axis=0)\n",
    "Xtrain2 = np.stack(Xtrain2, axis=0)\n",
    "Xtrain3 = np.stack(Xtrain3, axis=0)\n",
    "\n",
    "out_features = 19\n",
    "\n",
    "\n",
    "y_train_fusion = np.array([classes.index(x) for x in fusion_train_df.true])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickling the dataframes which have undergone inference from the base models\n",
    "\n",
    "# fusion_train_df.to_pickle('../data/fusion_train.pkl')\n",
    "# fusion_val_df.to_pickle('../data/fusion_val.pkl')\n",
    "# fusion_test_df.to_pickle('../data/fusion_test.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FusionModel(nn.Module):\n",
    "#     def __init__(self, model1, model2, model3, num_classes):\n",
    "#         super(FusionModel, self).__init__()\n",
    "#         self.model1 = model1\n",
    "#         self.model2 = model2\n",
    "#         self.model3 = model3\n",
    "#         self.fusion_layer = nn.Linear(num_classes * 3, num_classes)\n",
    "\n",
    "#     def forward(self, x1, x2, x3):\n",
    "        \n",
    "#         x = torch.cat((x1, x2, x3), dim=0)\n",
    "#         x = self.fusion_layer(x)\n",
    "\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PartialFusionModel(nn.Module):\n",
    "    def __init__(self, model1, model2, num_classes):\n",
    "        super(PartialFusionModel, self).__init__()\n",
    "        self.model1 = model1\n",
    "        self.model2 = model2\n",
    "        #self.model3 = model3\n",
    "        self.fusion_layer = nn.Linear(num_classes * 2, num_classes)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        \n",
    "        x = torch.cat((x1, x2), dim=0)\n",
    "        x = self.fusion_layer(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "# ## since I merged this into FusionModel with conditions after saving the weights, i need to try to recover the weights into \n",
    "# ## the new mdoel\n",
    "# # load components\n",
    "\n",
    "\n",
    "# #pmodel = PartialFusionModel(model_pix, meta_model, num_classes=19)\n",
    "\n",
    "# from config import model_paths\n",
    "# model_container = ModelContainer()\n",
    "\n",
    "# with open(model_paths['fusion_no_nlp'], 'rb') as file:\n",
    "#     partial_fusion_model = pickle.load(file)\n",
    "\n",
    "# fusion_model_with_partial_weights = FusionModel(models, num_classes=19, include_nlp=False)\n",
    "# fusion_model_with_partial_weights.fusion_layer.weight = nn.Parameter(partial_fusion_model.fusion_layer.weight)\n",
    "\n",
    "# # Save only the model weights (state_dict)\n",
    "# torch.save(fusion_model_with_partial_weights.state_dict(), '../models/fusion_model_no_nlp042123.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fusion_model = FusionModel\n",
    "\n",
    "\n",
    "# num_classes = 19  # Number of classes\n",
    "# pixel_model = model\n",
    "# fusion_model = FusionModel(meta_model, pixel_model, NLP_model, num_classes)\n",
    "# meta_and_pixel_fusion_model = PartialFusionModel(meta_model, pixel_model, num_classes)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(fusion_model.parameters(), lr=0.001)\n",
    "# p_optimizer = torch.optim.Adam(meta_and_pixel_fusion_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_epochs = 20\n",
    "# batch_size = 32\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     for i in range(0, len(y_train_fusion), batch_size):\n",
    "#         actual_batch_size = min(batch_size, len(Xtrain1) - i)\n",
    "#         X1_batch = torch.tensor(np.array(Xtrain1[i:i+actual_batch_size], dtype=np.float32), dtype=torch.float32)\n",
    "#         X2_batch = torch.tensor(np.array(Xtrain2[i:i+actual_batch_size], dtype=np.float32), dtype=torch.float32)\n",
    "#         X3_batch = torch.tensor(np.array(Xtrain3[i:i+actual_batch_size], dtype=np.float32), dtype=torch.float32)\n",
    "#         y_batch = torch.tensor(y_train_fusion[i:i+actual_batch_size], dtype=torch.long)\n",
    "\n",
    "#         # print(f\"X1_batch shape: {X1_batch.shape}\")\n",
    "#         # print(f\"X2_batch shape: {X2_batch.shape}\")\n",
    "#         # print(f\"X3_batch shape: {X3_batch.shape}\")\n",
    "#         # print(f\"y_batch shape: {y_batch.shape}\")\n",
    "\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = fusion_model(X1_batch, X2_batch, X3_batch)\n",
    "#         loss = criterion(outputs, y_batch)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#     print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xtest1 = fusion_test_df.meta_probs.values\n",
    "# Xtest2 = fusion_test_df.pixel_probs.values\n",
    "# Xtest3 = fusion_test_df.nlp_probs.values\n",
    "\n",
    "# Xtest1 = np.stack(Xtest1, axis=0)\n",
    "# Xtest2 = np.stack(Xtest2, axis=0)\n",
    "# Xtest3 = np.stack(Xtest3, axis=0)\n",
    "\n",
    "# out_features = 19\n",
    "\n",
    "# actual_classes = [0,2,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,23,25]\n",
    "# y_test_fusion = np.array([actual_classes.index(x) for x in fusion_test_df.true])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn.functional as F\n",
    "# # Evaluate the model with the test data\n",
    "# with torch.no_grad():\n",
    "#     X1_test_t = torch.tensor(Xtest1, dtype=torch.float32)\n",
    "#     X2_test_t = torch.tensor(Xtest2, dtype=torch.float32)\n",
    "#     X3_test_t = torch.tensor(Xtest3, dtype=torch.float32)\n",
    "#     y_test_t = torch.tensor(y_test_fusion, dtype=torch.long)\n",
    "\n",
    "#     outputs = fusion_model(X1_test_t, X2_test_t, X3_test_t)\n",
    "#     f_probabilities = F.softmax(outputs, dim=1)  # Apply softmax to the outputs\n",
    "\n",
    "#     _, f_predicted = torch.max(outputs, 1)\n",
    "#     correct = (f_predicted == y_test_t).sum().item()\n",
    "#     f_accuracy = correct / len(y_test_t) * 100\n",
    "\n",
    "# print(f'Test accuracy: {f_accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_batch(df, data_dir, destination_folder, write_labels=True):\n",
    "\n",
    "#     df1 = df.copy()\n",
    "#     #print('In batch, columns are: ', df1.columns)\n",
    "#     batch = df1.groupby('patientID').apply(lambda x: process_patient(x, data_dir, destination_folder, write_labels))\n",
    "    \n",
    "#     # print('writing labels into dicom in location ', dest_name)\n",
    "#     # for filename in batch.fname:\n",
    "\n",
    "#     return batch\n",
    "\n",
    "# def process_patient(patient_df, data_dir, destination_folder, write_labels):\n",
    "#     processed_exams = patient_df.groupby('exam').apply(lambda x: process_exam(x, data_dir, destination_folder, write_labels))\n",
    "#     return processed_exams\n",
    "\n",
    "\n",
    "# def process_exam(exam_df, data_dir, destination_folder, write_labels):\n",
    "#     # Group exam data by series and apply the process_series function\n",
    "#     processed_series = exam_df.groupby('series').apply(lambda x: process_series(x, data_dir, destination_folder, write_labels))\n",
    "\n",
    "#     #result = pd.concat(processed_series)\n",
    "#     result = processed_series\n",
    "#     return result\n",
    "    \n",
    "# def process_series(series_df, data_dir, destination_folder, write_labels, selection_fraction=0.5):\n",
    "#     # Sort the dataframe by file_info (or another relevant column)\n",
    "#     sorted_series = series_df.sort_values(by='fname')\n",
    "\n",
    "#     # Find the middle image index\n",
    "#     middle_index = int(len(sorted_series) * selection_fraction)\n",
    "\n",
    "#     # Get the middle image\n",
    "#     middle_image = sorted_series.iloc[middle_index]\n",
    "\n",
    "#     predicted_series_class, predicted_series_confidence = get_fusion_inference(middle_image)\n",
    "\n",
    "#     sorted_series['predicted_class'] = predicted_series_class\n",
    "#     sorted_series['prediction_confidence'] = np.round(predicted_series_confidence, 2)\n",
    "\n",
    "#     #save_path = f'/volumes/cm7/processed/modified/{series_df.patientID}/{series_df.exam}/{series_df[\"series\"]}/'\n",
    "\n",
    "#      # Define the save path relative to data_dir\n",
    "#     relative_path = os.path.relpath(series_df.fname.iloc[0], data_dir)\n",
    "#     save_path = os.path.join(data_dir, destination_folder, os.path.dirname(relative_path))\n",
    "\n",
    "#     if not os.path.exists(save_path):\n",
    "#         os.makedirs(save_path)\n",
    "\n",
    "#     if write_labels:\n",
    "#         #print('writing new data into', save_path)\n",
    "#         write_labels_into_dicom(sorted_series, label_num=predicted_series_class,\n",
    "#                             conf_num=np.round(predicted_series_confidence, 3), path=save_path)\n",
    "\n",
    "#     return sorted_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(df, data_dir, destination_folder, write_labels=True):\n",
    "\n",
    "    df1 = df.copy()\n",
    "    #print('In batch, columns are: ', df1.columns)\n",
    "    batch = df1.groupby('patientID').apply(lambda x: process_patient(x, data_dir, destination_folder, write_labels))\n",
    "    \n",
    "    # print('writing labels into dicom in location ', dest_name)\n",
    "    # for filename in batch.fname:\n",
    "\n",
    "    return batch\n",
    "\n",
    "def process_patient(patient_df, data_dir, destination_folder, write_labels):\n",
    "    processed_exams = patient_df.groupby('exam').apply(lambda x: process_exam(x, data_dir, destination_folder, write_labels))\n",
    "    return processed_exams\n",
    "\n",
    "\n",
    "def process_exam(exam_df, data_dir, destination_folder, write_labels):\n",
    "    # Group exam data by series and apply the process_series function\n",
    "    processed_series = exam_df.groupby('series').apply(lambda x: process_series(x, data_dir, destination_folder))\n",
    "\n",
    "    #result = pd.concat(processed_series)\n",
    "    result = processed_series\n",
    "    return result\n",
    "    \n",
    "def process_series(series_df, data_dir, destination_folder, write_labels, selection_fraction=0.5):\n",
    "    # Sort the dataframe by file_info (or another relevant column)\n",
    "    sorted_series = series_df.sort_values(by='fname')\n",
    "\n",
    "    # Find the middle image index\n",
    "    middle_index = int(len(sorted_series) * selection_fraction)\n",
    "\n",
    "    # Get the middle image\n",
    "    middle_image = sorted_series.iloc[middle_index]\n",
    "\n",
    "    predicted_series_class, predicted_series_confidence = get_fusion_model_prediction(middle_image)\n",
    "\n",
    "    sorted_series['predicted_class'] = predicted_series_class\n",
    "    sorted_series['prediction_confidence'] = np.round(predicted_series_confidence, 2)\n",
    "\n",
    "    #save_path = f'/volumes/cm7/processed/modified/{series_df.patientID}/{series_df.exam}/{series_df[\"series\"]}/'\n",
    "\n",
    "     # Define the save path relative to data_dir\n",
    "    relative_path = os.path.relpath(series_df.fname.iloc[0], data_dir)\n",
    "    save_path = os.path.join(data_dir, destination_folder, os.path.dirname(relative_path))\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    if write_labels:\n",
    "        #print('writing new data into', save_path)\n",
    "        write_labels_into_dicom(sorted_series, label_num=predicted_series_class,\n",
    "                            conf_num=np.round(predicted_series_confidence, 3), path=save_path)\n",
    "\n",
    "    return sorted_series\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_new_image_df(data_dir, dest_name='modified', write_labels = True):\n",
    "    # create the df of image data    \n",
    "    _, df = get_dicoms(data_dir)\n",
    "    df1 = df.copy()\n",
    "    ## manipulate df prior to evaluation\n",
    "    df1 = expand_filename(df1, ['blank', 'filename', 'series', 'exam', 'patientID'])\n",
    "    df1.drop(columns='blank', inplace=True)\n",
    "    df1['file_info']=df1.fname\n",
    "    df1['img_num'] = df1.file_info.apply(extract_image_number)\n",
    "    df1['contrast'] = df1.apply(detect_contrast, axis=1)\n",
    "    df1['plane'] = df1.apply(compute_plane, axis=1)\n",
    "    df1['series_num'] = df1.series.apply(lambda x: str(x).split('_')[-1])\n",
    "    #print('columns before preprocess are', df1.columns)\n",
    "\n",
    "    df1 = preprocess(df1)\n",
    "   # print('after preprocessin exam is in columns?', ('exam' in df1.columns))\n",
    "    #print('after preprocessing series is in columns?', ('series' in df1.columns))\n",
    "    #process the batch of studies\n",
    "    processed_frame = process_batch(df1, data_dir, dest_name, write_labels)\n",
    "\n",
    "    return processed_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_one_image(series, selection_fraction=0.5):\n",
    "    sorted_series = series.sort_values()\n",
    "    #print(sorted_series)\n",
    "    index = int(len(sorted_series) * selection_fraction)\n",
    "    print(index, len(sorted_series))\n",
    "    return sorted_series.iloc[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_one_from_series2(df, selection_fraction=0.5):\n",
    "    def select_one_image(series):\n",
    "        sorted_series = series.sort_values()\n",
    "        index = int(len(sorted_series) * selection_fraction)\n",
    "        return sorted_series.iloc[index]\n",
    "\n",
    "    df = df.sort_values(by=['patientID', 'series', 'file_info'])\n",
    "\n",
    "    grouped_df = df.groupby(['patientID', 'series'])\n",
    "    selected_rows = grouped_df.agg(select_one_image).reset_index()\n",
    "    \n",
    "    return selected_rows\n",
    "\n",
    "# Example usage\n",
    "# data = {'patientID': [1, 1, 1, 2, 2, 3, 3, 3, 3],\n",
    "#         'series': [1, 1, 2, 1, 2, 1, 1, 2, 2],\n",
    "#         'file_info': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I']}\n",
    "\n",
    "# df = pd.DataFrame(data)\n",
    "# selected_rows = mask_one_from_series(df, selection_fraction=0.5)\n",
    "# print(selected_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def filter_out_mv(df):\n",
    "#     # Create a boolean mask to identify rows with MultiValue objects in any column\n",
    "#     mask = df.applymap(lambda x: isinstance(x, MultiValue)).any(axis=1)\n",
    "#     #print(df[mask])\n",
    "#     # Invert the mask to select rows without MultiValue objects\n",
    "#     rows_without_multivalue = ~mask\n",
    "\n",
    "#     # Filter out rows with MultiValue objects in any column\n",
    "#     filtered_df = df[rows_without_multivalue]\n",
    "\n",
    "#     return mask, filtered_df\n",
    "\n",
    "#from pydicom.multival import MultiValue\n",
    "# def compute_plane_new(row):\n",
    "#     '''\n",
    "#     Computes the plane of imaging from the direction cosines provided in the `ImageOrientationPatient` field.\n",
    "#     The format of the values in this field is: `[x1, y1, z1, x2, y2, z2]`,\n",
    "#     which correspond to the direction cosines for the first row and column of the image pixel data.\n",
    "#     '''\n",
    "#     planes = ['sag', 'cor', 'ax']\n",
    "#     if 'ImageOrientationPatient1' in row.keys():\n",
    "#         dircos = [v for k, v in row.items() if 'ImageOrientationPatient' in k]\n",
    "#     else:\n",
    "#         dircos = row['ImageOrientationPatient']\n",
    "\n",
    "#         # Handle MultiValue objects by converting them to a list of floats\n",
    "#         if isinstance(dircos, MultiValue):\n",
    "#             dircos = [float(x) for x in dircos]\n",
    "\n",
    "#     # Check if dircos has the expected length\n",
    "#     if not isinstance(dircos, float) and len(dircos) == 6:\n",
    "#         dircos = np.array(dircos).reshape(2, 3)\n",
    "#         pnorm = abs(np.cross(dircos[0], dircos[1]))\n",
    "#         return planes[np.argmax(pnorm)]\n",
    "#     else:\n",
    "#         return 'unknown'\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MRI_project2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
