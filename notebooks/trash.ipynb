{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLAB_FLAG = False   # whether running on colab or locally on computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB_FLAG:\n",
    "    !pip install pydicom==2.1.2\n",
    "    !pip install monai seaborn sentence_transformers\n",
    "    !git clone 'https://github.com/mille055/AIPI540_individual_project.git'\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import pydicom\n",
    "#import monai\n",
    "import pickle\n",
    "import glob\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, recall_score, plot_confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from pprint import pprint\n",
    "from fastai.basics import delegates\n",
    "from fastcore.parallel import parallel\n",
    "from fastcore.utils import gt\n",
    "from fastcore.foundation import L\n",
    "\n",
    "# import monai\n",
    "# from monai.data import DataLoader, ImageDataset\n",
    "# from monai.transforms import AddChannel, Compose, RandRotate90, Resize, ScaleIntensity, EnsureType\n",
    "from pydicom.dataset import Dataset as DcmDataset\n",
    "from pydicom.tag import BaseTag as DcmTag\n",
    "from pydicom.multival import MultiValue as DcmMultiValue\n",
    "import sys\n",
    "import importlib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#local imports\n",
    "if COLAB_FLAG:\n",
    "    sys.path.append('/content/AIPI540_individual_project/scripts/')\n",
    "    train_datafile = '/content/AIPI540_individual_project/data/trainfiles.csv'\n",
    "    val_datafile = '/content/AIPI540_individual_project/data/valfiles.csv'\n",
    "    test_datafile = '/content/AIPI540_individual_project/data/testfiles.csv'\n",
    "\n",
    "else: # running locally\n",
    "    sys.path.append('/Users/cmm/Documents/GitHub/AIPI540_individual_project/scripts/')\n",
    "    train_datafile = '../data/trainfiles.csv'\n",
    "    val_datafile = '../data/valfiles.csv'\n",
    "    test_datafile = '../data/testfiles.csv'\n",
    "\n",
    "### local imports ###\n",
    "from config import file_dict, feats, feats_to_keep, column_lists, RF_parameters, classes, model_paths\n",
    "from config import abd_label_dict, val_list, train_val_split_percent, random_seed, data_transforms\n",
    "from config import sentence_encoder, series_description_column\n",
    "from utils import *\n",
    "#from train_pixel_model import train_pix_model, test_pix_model, ImgDataset, image_to_tensor, get_pixel_preds_and_probs\n",
    "#from train_meta_model import train_fit_parameter_trial, train_meta_model, calc_feature_importances, get_meta_probs, meta_inference\n",
    "#from train_text_model import train_text_log_model, load_text_data, get_nlp_inference\n",
    "from NLP.NLP_inference import get_NLP_inference\n",
    "from NLP.NLP_training import train_NLP_model\n",
    "from cnn.cnn_dataset import ImgDataset\n",
    "from cnn.cnn_inference import image_to_tensor, pixel_inference, test_pix_model, load_pixel_model, visualize_results\n",
    "from cnn.cnn_model import CustomResNet50\n",
    "from cnn.cnn_data_loaders import get_data_loaders\n",
    "from metadata.meta_inference import meta_inference, calc_feature_importances\n",
    "from metadata.meta_training import train_fit_parameter_trial, train_meta_model, evaluate_meta_model\n",
    "from fusion_model.fus_model import FusionModel\n",
    "from fusion_model.fus_inference import get_fusion_inference\n",
    "from model_container import ModelContainer\n",
    "from process_tree import Processor, write_labels_into_dicom\n",
    "# from AIPI540_individual_project.scripts.train_pixel_model import train_model\n",
    "# from AIPI540_individual_project.scripts.train_text_model import load_text_data, train_text_model, list_incorrect_text_predictions\n",
    "# from AIPI540_individual_project.scripts.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_model = FusionModel\n",
    "\n",
    "class PartialFusionModel(nn.Module):\n",
    "    def __init__(self, model1, model2, num_classes):\n",
    "        super(PartialFusionModel, self).__init__()\n",
    "        self.model1 = model1\n",
    "        self.model2 = model2\n",
    "        #self.model3 = model3\n",
    "        self.fusion_layer = nn.Linear(num_classes * 2, num_classes)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        \n",
    "        x = torch.cat((x1, x2), dim=0)\n",
    "        x = self.fusion_layer(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "partial_fusion_model = PartialFusionModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FusionModel(\n",
      "  (model2): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Linear(in_features=2048, out_features=19, bias=True)\n",
      "  )\n",
      "  (fusion_layer): Linear(in_features=57, out_features=19, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "with open('../models/fusion_model041623.pkl', 'rb') as file:\n",
    "    fusion = pickle.load(file)\n",
    "\n",
    "print(fusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### fix my fusion model issue:; have to change from a pickled model to saved weights\n",
    "def save_fusion_model_weights(pickle_path, weight_path):\n",
    "    with open(pickle_path, 'rb') as file:\n",
    "        fusion_model = pickle.load(file)\n",
    "    torch.save(fusion_model.state_dict(), weight_path)\n",
    "\n",
    "save_fusion_model_weights(model_paths['fusion'], '../models/fusion_saved_weights042123.pth')\n",
    "save_fusion_model_weights('../models/meta_and_pixel_fusion_model041623.pkl', '../models/fusion_saved_weights_no_nlp042123.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### in the fusion model creation code:\n",
    "\n",
    "Xtrain1 = fusion_train_df.meta_probs.values\n",
    "\n",
    "Xtrain2 = fusion_train_df.pixel_probs.values\n",
    "Xtrain3 = fusion_train_df.nlp_probs.values\n",
    "\n",
    "Xtrain1 = np.stack(Xtrain1, axis=0)\n",
    "Xtrain2 = np.stack(Xtrain2, axis=0)\n",
    "Xtrain3 = np.stack(Xtrain3, axis=0)\n",
    "\n",
    "out_features = 19\n",
    "\n",
    "\n",
    "y_train_fusion = np.array([classes.index(x) for x in fusion_train_df.true])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickling the dataframes which have undergone inference from the base models\n",
    "\n",
    "# fusion_train_df.to_pickle('../data/fusion_train.pkl')\n",
    "# fusion_val_df.to_pickle('../data/fusion_val.pkl')\n",
    "# fusion_test_df.to_pickle('../data/fusion_test.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FusionModel(nn.Module):\n",
    "#     def __init__(self, model1, model2, model3, num_classes):\n",
    "#         super(FusionModel, self).__init__()\n",
    "#         self.model1 = model1\n",
    "#         self.model2 = model2\n",
    "#         self.model3 = model3\n",
    "#         self.fusion_layer = nn.Linear(num_classes * 3, num_classes)\n",
    "\n",
    "#     def forward(self, x1, x2, x3):\n",
    "        \n",
    "#         x = torch.cat((x1, x2, x3), dim=0)\n",
    "#         x = self.fusion_layer(x)\n",
    "\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PartialFusionModel(nn.Module):\n",
    "    def __init__(self, model1, model2, num_classes):\n",
    "        super(PartialFusionModel, self).__init__()\n",
    "        self.model1 = model1\n",
    "        self.model2 = model2\n",
    "        #self.model3 = model3\n",
    "        self.fusion_layer = nn.Linear(num_classes * 2, num_classes)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        \n",
    "        x = torch.cat((x1, x2), dim=0)\n",
    "        x = self.fusion_layer(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "# ## since I merged this into FusionModel with conditions after saving the weights, i need to try to recover the weights into \n",
    "# ## the new mdoel\n",
    "# # load components\n",
    "\n",
    "\n",
    "# #pmodel = PartialFusionModel(model_pix, meta_model, num_classes=19)\n",
    "\n",
    "# from config import model_paths\n",
    "# model_container = ModelContainer()\n",
    "\n",
    "# with open(model_paths['fusion_no_nlp'], 'rb') as file:\n",
    "#     partial_fusion_model = pickle.load(file)\n",
    "\n",
    "# fusion_model_with_partial_weights = FusionModel(models, num_classes=19, include_nlp=False)\n",
    "# fusion_model_with_partial_weights.fusion_layer.weight = nn.Parameter(partial_fusion_model.fusion_layer.weight)\n",
    "\n",
    "# # Save only the model weights (state_dict)\n",
    "# torch.save(fusion_model_with_partial_weights.state_dict(), '../models/fusion_model_no_nlp042123.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fusion_model = FusionModel\n",
    "\n",
    "\n",
    "# num_classes = 19  # Number of classes\n",
    "# pixel_model = model\n",
    "# fusion_model = FusionModel(meta_model, pixel_model, NLP_model, num_classes)\n",
    "# meta_and_pixel_fusion_model = PartialFusionModel(meta_model, pixel_model, num_classes)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(fusion_model.parameters(), lr=0.001)\n",
    "# p_optimizer = torch.optim.Adam(meta_and_pixel_fusion_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_epochs = 20\n",
    "# batch_size = 32\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     for i in range(0, len(y_train_fusion), batch_size):\n",
    "#         actual_batch_size = min(batch_size, len(Xtrain1) - i)\n",
    "#         X1_batch = torch.tensor(np.array(Xtrain1[i:i+actual_batch_size], dtype=np.float32), dtype=torch.float32)\n",
    "#         X2_batch = torch.tensor(np.array(Xtrain2[i:i+actual_batch_size], dtype=np.float32), dtype=torch.float32)\n",
    "#         X3_batch = torch.tensor(np.array(Xtrain3[i:i+actual_batch_size], dtype=np.float32), dtype=torch.float32)\n",
    "#         y_batch = torch.tensor(y_train_fusion[i:i+actual_batch_size], dtype=torch.long)\n",
    "\n",
    "#         # print(f\"X1_batch shape: {X1_batch.shape}\")\n",
    "#         # print(f\"X2_batch shape: {X2_batch.shape}\")\n",
    "#         # print(f\"X3_batch shape: {X3_batch.shape}\")\n",
    "#         # print(f\"y_batch shape: {y_batch.shape}\")\n",
    "\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = fusion_model(X1_batch, X2_batch, X3_batch)\n",
    "#         loss = criterion(outputs, y_batch)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#     print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item()}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MRI_project2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
